{
  "model_type": "improved",
  "dataset_type": "hard",
  "num_epochs": 100,
  "batch_size": 32,
  "learning_rate": 0.001,
  "vocab_size": 110,
  "train_size": 800,
  "val_size": 200,
  "best_val_acc": 4.5,
  "final_train_acc": 66.25,
  "training_time": 168.6195170879364,
  "train_losses": [
    4.716536750793457,
    4.700574359893799,
    4.694381790161133,
    4.6853759765625,
    4.665030117034912,
    4.620783348083496,
    4.548341274261475,
    4.489560871124268,
    4.423040447235107,
    4.408704223632813,
    4.314886379241943,
    4.20701979637146,
    4.087985992431641,
    3.995817756652832,
    3.917818603515625,
    3.841268787384033,
    3.769041347503662,
    3.73830961227417,
    3.604809684753418,
    3.4908178424835206,
    3.4232516288757324,
    3.3052690410614014,
    3.281863880157471,
    3.2074781799316407,
    3.1836087894439697,
    3.0929094886779787,
    3.0804827117919924,
    2.9064131450653075,
    2.8699803733825684,
    2.7779392528533937,
    2.692010660171509,
    2.628657007217407,
    2.5145835208892824,
    2.45807430267334,
    2.384451389312744,
    2.2721575832366945,
    2.1666280031204224,
    2.1341616201400755,
    2.0443213319778444,
    2.015343956947327,
    1.9775459051132203,
    1.891240620613098,
    1.8553506851196289,
    1.7868785762786865,
    1.7461410856246948,
    1.6844660997390748,
    1.6807961559295654,
    1.6104425048828126,
    1.6381741905212401,
    1.601954035758972,
    1.6009999227523803,
    1.5288399839401245,
    1.516767568588257,
    1.5448029327392578,
    1.5052788209915162,
    1.5186962604522705,
    1.5036991405487061,
    1.4331490898132324,
    1.4509816789627075,
    1.4167612028121948,
    1.4490061378479004,
    1.4777152252197265,
    1.4078673839569091,
    1.399814682006836,
    1.425379090309143,
    1.3898059225082398,
    1.386704797744751,
    1.4290376710891723,
    1.4532660913467408,
    1.4577867555618287,
    1.403708384037018,
    1.4574101305007934,
    1.3857725381851196,
    1.4176312351226807,
    1.451524109840393,
    1.3928095483779908,
    1.3990146827697754,
    1.4265805244445802,
    1.3654151344299317,
    1.4346176815032958,
    1.4295351362228395,
    1.4003227758407593,
    1.3676812219619752,
    1.4282926082611085,
    1.3896896934509277,
    1.3684823417663574,
    1.40082013130188,
    1.440746111869812,
    1.3992463612556458,
    1.44363338470459,
    1.4722133493423462,
    1.3767410278320313,
    1.3807764101028441,
    1.3534312009811402,
    1.4266488027572632,
    1.3641196012496948,
    1.421475248336792,
    1.4174315690994264,
    1.3744820857048035,
    1.3680603075027467
  ],
  "train_accs": [
    0.875,
    0.375,
    1.25,
    1.375,
    1.125,
    1.25,
    1.5,
    2.125,
    3.25,
    2.5,
    3.0,
    3.5,
    4.25,
    5.375,
    5.0,
    6.75,
    5.5,
    7.125,
    7.625,
    10.5,
    10.625,
    13.75,
    12.25,
    11.875,
    13.125,
    14.5,
    16.875,
    21.75,
    20.25,
    21.25,
    24.875,
    26.375,
    29.375,
    30.625,
    31.375,
    34.25,
    39.875,
    39.0,
    43.5,
    42.25,
    42.875,
    47.5,
    47.375,
    51.75,
    52.125,
    54.0,
    51.875,
    57.625,
    55.625,
    57.625,
    55.625,
    60.375,
    60.5,
    58.0,
    58.5,
    60.375,
    58.625,
    63.5,
    61.0,
    62.75,
    61.375,
    61.5,
    64.375,
    64.75,
    62.625,
    64.125,
    64.0,
    62.875,
    60.875,
    62.5,
    63.75,
    61.625,
    63.75,
    63.125,
    61.625,
    64.125,
    62.5,
    62.625,
    66.25,
    62.625,
    62.25,
    64.875,
    65.125,
    63.5,
    62.5,
    65.125,
    64.125,
    63.375,
    64.25,
    62.625,
    62.5,
    64.375,
    65.75,
    65.75,
    64.625,
    66.25,
    62.75,
    62.875,
    65.0,
    66.25
  ],
  "val_losses": [
    4.704411915370396,
    4.707275526864188,
    4.714728968484061,
    4.725196089063372,
    4.82113334110805,
    4.80978080204555,
    4.660229342324393,
    4.720843383244106,
    4.618377753666469,
    4.579920155661447,
    4.563414982386997,
    4.537329946245466,
    4.438493728637695,
    4.355790002005441,
    4.3676742144993375,
    4.332245826721191,
    4.332016127450125,
    4.346534797123501,
    4.325833661215646,
    4.402051993778774,
    4.401056698390415,
    4.388961383274624,
    4.671254362378802,
    4.468071665082659,
    4.501967293875558,
    4.5360950742449075,
    4.6059063502720425,
    4.64243221282959,
    4.546479497637067,
    4.700639929090228,
    4.729432650974819,
    4.819197314126151,
    4.692331995282855,
    4.786692687443325,
    4.742368493761335,
    4.763191904340472,
    4.910536425454276,
    4.8893875394548685,
    4.983632837023054,
    5.1742722647530695,
    4.978673866816929,
    5.052019255501883,
    4.950462886265346,
    5.032283306121826,
    5.035612923758371,
    5.089830534798758,
    5.109198638371059,
    5.070008209773472,
    5.134961809430804,
    5.14866270337786,
    5.090335777827671,
    5.119878496442523,
    5.070331232888358,
    5.106927667345319,
    5.164934567042759,
    5.190764086587088,
    5.122005803244455,
    5.116152627127511,
    5.151244980948312,
    5.1478864806038995,
    5.158044270106724,
    5.1517156192234586,
    5.125255925314767,
    5.119633061545236,
    5.121699946267264,
    5.112134388514927,
    5.1109546933855325,
    5.130577836717878,
    5.144862311226981,
    5.160181522369385,
    5.149956975664411,
    5.155724934169224,
    5.152499743870327,
    5.139040606362479,
    5.153720378875732,
    5.147851807730539,
    5.1729616437639505,
    5.144537040165493,
    5.141052995409284,
    5.148595196860177,
    5.134749753134591,
    5.128804956163679,
    5.145326478140695,
    5.140435150691441,
    5.160065446581159,
    5.154837948935373,
    5.143439565386091,
    5.131397656032017,
    5.120261532919748,
    5.158225059509277,
    5.1526667049952914,
    5.161656992776053,
    5.1414986337934225,
    5.12759120123727,
    5.14506162915911,
    5.143857819693429,
    5.150634561266218,
    5.120555741446359,
    5.1659954616001675,
    5.167474610464914
  ],
  "val_accs": [
    1.5,
    0.0,
    0.5,
    0.0,
    0.0,
    0.5,
    0.5,
    0.5,
    0.5,
    0.5,
    0.5,
    0.5,
    0.5,
    0.5,
    1.0,
    1.5,
    1.0,
    1.0,
    0.5,
    1.5,
    1.0,
    0.5,
    1.5,
    1.0,
    2.0,
    0.5,
    2.0,
    2.5,
    2.0,
    1.5,
    2.0,
    1.5,
    2.5,
    1.0,
    2.0,
    2.5,
    4.0,
    3.0,
    2.5,
    2.5,
    4.0,
    3.0,
    2.5,
    4.5,
    2.0,
    2.0,
    2.5,
    1.5,
    2.5,
    3.0,
    1.5,
    3.0,
    2.0,
    3.0,
    2.0,
    2.5,
    3.0,
    3.5,
    2.5,
    3.0,
    3.5,
    2.5,
    3.5,
    3.5,
    3.0,
    3.5,
    3.0,
    3.0,
    2.5,
    3.5,
    3.0,
    3.0,
    3.0,
    3.0,
    3.0,
    3.0,
    3.5,
    3.0,
    2.5,
    2.0,
    2.5,
    2.5,
    2.5,
    2.5,
    3.5,
    4.0,
    3.0,
    2.5,
    2.5,
    4.0,
    3.0,
    3.0,
    2.5,
    2.5,
    3.0,
    3.0,
    3.0,
    2.5,
    3.5,
    2.5
  ],
  "challenges": [
    "Low accuracy at epoch 6: 0.50%",
    "Low accuracy at epoch 7: 0.50%",
    "Low accuracy at epoch 8: 0.50%",
    "Low accuracy at epoch 9: 0.50%",
    "Low accuracy at epoch 10: 0.50%",
    "Low accuracy at epoch 11: 0.50%",
    "Low accuracy at epoch 12: 0.50%",
    "Low accuracy at epoch 13: 0.50%",
    "Low accuracy at epoch 14: 1.00%",
    "Low accuracy at epoch 15: 1.50%",
    "Low accuracy at epoch 16: 1.00%",
    "Low accuracy at epoch 17: 1.00%",
    "Low accuracy at epoch 18: 0.50%",
    "Low accuracy at epoch 19: 1.50%",
    "Low accuracy at epoch 20: 1.00%",
    "Low accuracy at epoch 21: 0.50%",
    "Low accuracy at epoch 22: 1.50%",
    "Low accuracy at epoch 23: 1.00%",
    "Low accuracy at epoch 24: 2.00%",
    "Low accuracy at epoch 25: 0.50%",
    "Low accuracy at epoch 26: 2.00%",
    "Low accuracy at epoch 27: 2.50%",
    "Low accuracy at epoch 28: 2.00%",
    "Low accuracy at epoch 29: 1.50%",
    "Low accuracy at epoch 30: 2.00%",
    "Low accuracy at epoch 31: 1.50%",
    "Low accuracy at epoch 32: 2.50%",
    "Low accuracy at epoch 33: 1.00%",
    "Low accuracy at epoch 34: 2.00%",
    "Low accuracy at epoch 35: 2.50%",
    "Low accuracy at epoch 36: 4.00%",
    "Low accuracy at epoch 37: 3.00%",
    "Low accuracy at epoch 38: 2.50%",
    "Low accuracy at epoch 39: 2.50%",
    "Low accuracy at epoch 40: 4.00%",
    "Low accuracy at epoch 41: 3.00%",
    "Low accuracy at epoch 42: 2.50%",
    "Low accuracy at epoch 43: 4.50%",
    "Low accuracy at epoch 44: 2.00%",
    "Low accuracy at epoch 45: 2.00%",
    "Low accuracy at epoch 46: 2.50%",
    "Low accuracy at epoch 47: 1.50%",
    "Low accuracy at epoch 48: 2.50%",
    "Low accuracy at epoch 49: 3.00%",
    "Low accuracy at epoch 50: 1.50%",
    "Low accuracy at epoch 51: 3.00%",
    "Low accuracy at epoch 52: 2.00%",
    "Low accuracy at epoch 53: 3.00%",
    "Low accuracy at epoch 54: 2.00%",
    "Low accuracy at epoch 55: 2.50%",
    "Low accuracy at epoch 56: 3.00%",
    "Low accuracy at epoch 57: 3.50%",
    "Low accuracy at epoch 58: 2.50%",
    "Low accuracy at epoch 59: 3.00%",
    "Low accuracy at epoch 60: 3.50%",
    "Low accuracy at epoch 61: 2.50%",
    "Low accuracy at epoch 62: 3.50%",
    "Low accuracy at epoch 63: 3.50%",
    "Low accuracy at epoch 64: 3.00%",
    "Low accuracy at epoch 65: 3.50%",
    "Low accuracy at epoch 66: 3.00%",
    "Low accuracy at epoch 67: 3.00%",
    "Low accuracy at epoch 68: 2.50%",
    "Low accuracy at epoch 69: 3.50%",
    "Low accuracy at epoch 70: 3.00%",
    "Low accuracy at epoch 71: 3.00%",
    "Low accuracy at epoch 72: 3.00%",
    "Low accuracy at epoch 73: 3.00%",
    "Low accuracy at epoch 74: 3.00%",
    "Low accuracy at epoch 75: 3.00%",
    "Low accuracy at epoch 76: 3.50%",
    "Low accuracy at epoch 77: 3.00%",
    "Low accuracy at epoch 78: 2.50%",
    "Low accuracy at epoch 79: 2.00%",
    "Low accuracy at epoch 80: 2.50%",
    "Low accuracy at epoch 81: 2.50%",
    "Low accuracy at epoch 82: 2.50%",
    "Low accuracy at epoch 83: 2.50%",
    "Low accuracy at epoch 84: 3.50%",
    "Low accuracy at epoch 85: 4.00%",
    "Low accuracy at epoch 86: 3.00%",
    "Low accuracy at epoch 87: 2.50%",
    "Low accuracy at epoch 88: 2.50%",
    "Low accuracy at epoch 89: 4.00%",
    "Low accuracy at epoch 90: 3.00%",
    "Low accuracy at epoch 91: 3.00%",
    "Low accuracy at epoch 92: 2.50%",
    "Low accuracy at epoch 93: 2.50%",
    "Low accuracy at epoch 94: 3.00%",
    "Low accuracy at epoch 95: 3.00%",
    "Low accuracy at epoch 96: 3.00%",
    "Low accuracy at epoch 97: 2.50%",
    "Low accuracy at epoch 98: 3.50%",
    "Low accuracy at epoch 99: 2.50%"
  ],
  "solutions": [
    "Use data augmentation (rotation, scaling)",
    "Increase model capacity or use pre-trained features",
    "Implement curriculum learning (train on easy first)",
    "Implement early stopping to prevent overfitting",
    "Use learning rate warmup"
  ]
}